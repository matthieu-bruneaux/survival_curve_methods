---
title: "Fitting survival curves to real life data."
author: "Daniel Padfield"
format:
  html:
    toc: true
    toc-depth: 2
    toc-title: 'Contents'
    code-overflow: wrap
    code-fold: true
    code-tools: true
    self-contained: true
editor: visual
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  #tidy.opts=list(width.cutoff=60),
  #tidy=TRUE,
  fig.align = 'center',
  warning=FALSE,
  message = FALSE
)

here::i_am('scripts/survival_curves_using_real_data.qmd')
```

## Introduction

Virulence assays using animal models (such as the waxmoth larvae *Galleria melonella*) have become increasingly popular for studying virulence of microbes, viruses, and fungi. Generally these assays involve injecting bacteria into the many insects and then tracking time to death of multiple individuals.

Microbiologists take great care in the care and selection of the animal being used as the virulence model. For example, for *Galleria* we make sure to standardise the source, care, and preparation of the model organism (amongst other things) to try and minimise differences between individuals that could add unwanted variation to our results.

However, primers and advice on how to analyse survival curve data in microbiology remains lacking. TIf we do not take the same care in our analyses as we do in our curation of the data, we risk making conclusions that are not adequately supported by the dataset.

This primer aims to walk through a real life dataset and shows a common pitfall in the analysis of these types of experiments where each *Galleria* is not independent from each other. This non-independence impacts the way we do significance testing and can result in false positives (where we think there is a significant effect where there isn't). In demonstrating the problem, we also show how to fit and visualise survival curves in multiple ways that are summarised below.

### Methods of fitting survival curves implemented

-   Fitting a Cox proportional hazards model using **coxph()**. The survival curves for this model can be visualised using **ggsurvplot()**.

-   Fitting a hierarchical (mixed effects model) Cox proportional hazards model using **coxme()**. There is currently no way of visualising the survival curves of a hierarchical Cox proportional hazards model.

-   Fitting Bayesian survival curves using **rstanarm**. These can easily be made hierarchical to account for random effects. The survival curves for this model can easily be visualised using **rstanarm** and **ggplot**.

-   Fitting Bayesian survival curves using **brms**. The survival curve can be visualised in a similar using these methods: https://github.com/paul-buerkner/brms/issues/966. The addition of the cox model is explained here: https://github.com/paul-buerkner/brms/issues?q=is%3Aissue+cox+is%3Aclosed

-   Using a piecewise-exponential model that allows us to model the hazard using a poisson regression https://discourse.mc-stan.org/t/using-stan-jm-for-parametric-proportional-hazards-regression-only/3931/3

### The dataset and the problem of non-independence

We will first read in the dataset and have a look at the columns and structure of the dataset. The dataset is from an experiment a colleague ran where he injected bacteria into *Galleria melonella* and tracked how long it took them to die.

The bacterial clones (`d$clone`) had been isolated from different treatments that had contained lime or not (probably calcium carbonate) (`d$treat1`) and been cultured in a shaken or static environment (`d$treat2`).

```{r read_data}
# load in first package
library(tidyverse) # install.packages('tidyverse')

# read in dataset
d <- read.csv(here::here('data/real_life_data.csv'))

# look at the structure of the dataframe
str(d)

# look at unique clone values
unique(d$clone)

# look at unique values for treatments
unique(d$treat1)
unique(d$treat2)

# how many clones do we have per treatment combination
select(d, clone, treat1, treat2) %>%
  distinct() %>%
  group_by(treat1, treat2) %>%
  tally()
```

The column definitions are as follows:

-   `clone` is the bacterial clone

-   `time_of_death` is the time to death in hours

-   `treat1` is whether the bacteria were evolved in the presence of lime or not

-   `treat2` is whether the bacteria were evolved in while being shaken or static

-   `status` is whether the Galleria was dead (1) or alive (0). Zeroes are right censored data where the individuals do not die during the experiment.

In this experiment the same individual clone was injected into multiple individuals and this is an increasingly common practice in experiments looking at the evolution of virulence in microbes. Our question is whether virulence (the survival curves) are different between our treatments. We have six individual clones per treatment combination, and need to account for the non-independence of when insect larvae have been injected with the same bacterial clone.

Understanding the structure of your data, and how it impacts the analysis you do, is important to think about BEFORE collecting your data during your experimental design.

We will now load in the packages needed for variety of ways we demonstrate fitting survival curves in R.

## Analysing survival curves

### Load in packages

Firstly we will load in the packages used for analysing survival curves. Most are easily installable (the code to install them is to the right of each command as a comment). The survival analysis code from **rstanarm** is currently on a development branch on GitHub, so is a bit more involved to install, but it SHOULD be ok following the code provided.

```{r load_packages}

# load in packages
library(survival) # install.packages('survival')
library(survminer) # install.packages('survminer')
library(coxme) # install.packages('coxme')
library(rstanarm) # clone repository into directory of choice using "git clone -b feature/survival https://github.com/stan-dev/rstanarm.git" in your terminal. Open the R project and run devtools::document(). Then run devtools::install() to install the development version of rstanarm.
library(tidybayes) # install.packages('tidybayes')
library(patchwork) # install.packages('patchwork')
library(pammtools) # install.packages("pammtools")
library(brms) # install.packages('brms')
library(ggdist) # install.packages('ggdist')
```

We can then start running through the analyses.

### Running a Cox proportional hazards model

The most common (and simplest) way of running a survival curve analysis is to do a Cox proportional hazards model using **survival::coxph()**. These can then be visualised using **survminer::ggsurvplot()** amongst other methods.

The function **coxph()** allows us to use classic likelihood ratio tests using **anova()** to test for the significance of individual factors and interactions. So we will start off with the most complex model with an interaction between treat1 and treat2 and then simplify from there.

```{r cox_model}

# do coxph regression and model simplification
model <- coxph(Surv(time_of_death, status) ~ treat1*treat2, data=d)
model2 <- coxph(Surv(time_of_death, status) ~ treat1 + treat2, data=d)
anova(model, model2)
# this term is not significant

model3 <- coxph(Surv(time_of_death, status) ~ treat2, data=d)
anova(model2, model3)
# this term (treat1) is not significant 

model4 <- coxph(Surv(time_of_death, status) ~ treat1, data=d)
anova(model2, model4)
# this term (treat2) is significant

model5 <- coxph(Surv(time_of_death, status) ~ 1, data=d)
anova(model3, model5)
anova(model4, model5)
# confirmation that model3 is the best model
```

So from this process we can see that model3 is the best model. This model says there is likely differential survival for larvae injected with bacteria that were evolved under shaken or static conditions.

The survival curves can be visualised using **survfit()** methods.

```{r cox_model_plot}
#| fig.height: 6
#| fig.width: 10

# create predictions
model_preds <- survfit(Surv(time_of_death, status)~treat2, data=d)
# summary(model_preds)

# plot survival curve
p1 <- ggsurvplot(model_preds, data = d, legend = "right", legend.title = "Treatment", ggtheme = theme_bw(), conf.int = TRUE, linetype = c(1), palette = "Paired2", censor = FALSE, legend.labs = c('shaken', 'static'), xlab = "Time (Hours)", ylab = "Proportion Alive", font.y = c(15), font.x = c(15), font.tickslab = c(15), conf.int.alpha = 0.15)
p2 <- ggforest(model3, data = d, main = "Treatment impacts on Pseudomonas virulence", fontsize = 0.5)

p1$plot + p2 + plot_layout(ncol = 2)

```

So this model finds that bacteria evolved under shaken conditions are more virulent (larvae have worse survival) than bacteria evolved under static conditions. The hazards ratio between shaken and static is the exponent of the log hazard (which is the coef) in the output of the Cox model. This can be extracted using **exp(coef(model3)** and is 0.65 in this instance, meaning that 0.65 times as many larvae injected with static bacteria are dying as compared to larvae injected with shaken bacteria. Stated differently, shaken bacteria are significantly more virulent than static bacteria in these data.

However, some of these larvae have been injected with exactly the same bacterial clone, so are not independent. This alters the residual degrees of freedom of the model and makes us more likely to find significance if we do not account for this non-independence.

### Running a hierarchical (mixed effects) Cox proportional hazards model

We can run a mixed effects (hierarchical) Cox proportional hazards model with **coxme::coxme()**. We will just see whether our best model using the non-hierarchical method is still significant (does treat2 still matter when accounting for non-independence of our larvae).

```{r coxme_model}

# originally using a standard cox model
model_me <- coxme(Surv(time_of_death, status)~treat2 + (1|clone), d)
model_me
model_me2 <- coxme(Surv(time_of_death, status)~1 + (1|clone), d)
anova(model_me, model_me2)
# no longer significant
```

After accounting for the fact that the same clone was injected into multiple larvae, the effect of static vs. shaken bacteria is no longer significant.

The hazard ratio for the mixed effects model is the same as for the standard Cox model at 0.64, but the standard error of the coefficient is much larger (0.37 compared to 0.11).

It would be nice to be able to visualise the survival curves as for the standard Cox model, but this seems tricky for **coxme**. What we can do is produce clone-level survival curves and then plot them along with the treatment level curves, to see how much variation across clones there is within and between our treatments. This is not the

```{r plot_coxme}
#| fig.width: 7
#| fig.height: 5

# create predictions
model_preds <- survfit(Surv(time_of_death, status)~treat2, data=d)
model_preds_clone <- survfit(Surv(time_of_death, status)~clone, data=d)

# make plot, grab data to plot again
p1_data <- ggsurvplot(model_preds) %>%
  .$plot %>%
  .$data %>%
  select(time, surv, treat2, upper, lower) %>%
  mutate(treat2 = as.character(treat2))
p2_data <- ggsurvplot(model_preds_clone) %>%
  .$plot %>%
  .$data %>%
  select(time, surv, clone, upper, lower) %>%
  mutate(clone = as.character(clone)) %>%
  left_join(., select(d, treat2, clone) %>% distinct())

# overlay treatment plot with clone level estimates
ggplot() +
  geom_stepribbon(aes(x = time, ymin = lower, ymax = upper, fill = treat2), alpha = 0.1, p1_data) +
  geom_step(aes(time, surv, col = treat2, group = clone), alpha = 0.5, p2_data) +
  geom_step(aes(time, surv, col = treat2), p1_data, linewidth = 1.5) +
  theme_bw()
```

In this plot, the thick lines are the treatment-level effects, and the thinner lines are the individual clones. We can see that there are clones in the static treatment that are really virulent, causing 100% mortality as quickly as the most virulent shaken bacteria. It is this clone-variation that is likely making causing the significance in the original Cox model, and the reason why accounting for it removes the significant effect of shaken vs. static.

**coxme** is fine here and allows us to account for the non-independence of our data. But relatively new methods have been implemented in a Bayesian framework that allow for us to better visualise and understand the uncertainty in our data. These approaches have been implemented in the Stan coding language and implemented in **brms** and **rstanarm**. We shall show examples of both of these in turn.

### Running a Bayesian Cox proportional hazards model using brms

The popular Bayesian analysis package **brms** has implemented the Cox family that allows for Bayesian Cox proportional hazards models.

```{r brms_model}
#| message: false
#| output: false

fit_brms <- brm(time_of_death | cens(1 - status) ~ treat2 + (1|clone), 
            data = d, 
            family = brmsfamily("cox"),
            chains = 3,
            iter = 3000)

```

```{r brms_output}
fit_brms
```

This recreates the **coxme** model. We can see the estimate (which represents the log hazard) for the static populations is -0.49, making the hazard ratio estimate 0.61, which is very similar to that of **coxph()** and **coxme()**. However we can look at the distribution of the parameter estimates to calculate credible intervals and look at the uncertainty around our estimate of the hazard ratio.

We will do this using the great packages **tidybayes** and **ggdist**.

```{r brms_hazard}
#| fig.height: 4
#| fig.width: 7

# look at what parameters are possible
get_variables(fit_brms)
# loads

# choose only the main effect
brms_hr <- fit_brms %>%
  gather_draws(`b_treat2static`, regex = TRUE) %>%
  mutate(hazard_ratio = exp(.value))

# make plot
ggplot(brms_hr, aes(y = .variable, x = hazard_ratio)) +
  geom_vline(aes(xintercept = 1), linetype = 2) +
  stat_eye(aes(fill = stat(level)), alpha = 0.8) +
  theme_bw(base_size = 14) +
  scale_fill_brewer(na.translate = FALSE) +
  labs(y = '') +
  theme(legend.position = c(0.8, 0.8)) 

```

From this we can see that our estimated hazard ratio has 95% credible intervals that encompass 1 (median hazard ratio = 0.62, 95%CI = 0.271-1.36), which if we wanted to interpret in a frequentist manner would mean that whether the bacteria were grown statically or shaken does not alter the survival probability of the larvae.

It may be possible to plot the survival curve using **brms** but it is not a simple procedure. See [here](https://discourse.mc-stan.org/t/plotting-survival-plots-after-brm/14226) for a brief discussion of how to do it.

We can use a great online workthrough of the survival book by Solomon Kurz. [Chapter 13.3](https://bookdown.org/content/4253/describing-continuous-time-event-occurrence-data.html#the-kaplan-meier-method-of-estimating-the-continuous-time-survivor-function) demonstrates to create a Kaplan-Meier curve using **brms**.

However, it is not straightforward to sample from the posterior distribution of a Cox model in **brms**, so the visualisation possibilities for the survival curve are limited.

We might be able to manually get a prediction for a larvae in each group by calculating the baseline hazard through time and then multiplying this by each of the posterior draws. See [here](https://discourse.mc-stan.org/t/manual-absolute-predictions-from-cox-model-in-brms/27966/8) for an example, which links to [here](https://stats.stackexchange.com/questions/36015/prediction-in-cox-regression).

### Running an M-splines hazards model using rstanarm

There has also been a lot of development in the Bayesian analysis R package **rstanarm** to allow for the fitting of survival curves. All of these treat times as a continuous predictor. Here we will fit the default M-splines model.

```{r rstanarm_model}
# do an analysis using rstanarm
mod_rstanarm <- stan_surv(Surv(time_of_death, status) ~ treat2 + (1|clone),
                        data = d,
                        chains = 3,
                        cores = 3,
                        seed = 42,
                        iter = 3000)

mod_rstanarm
```

### Running a piecewise-exponential model using brms

The piecewise-exponential model divides the time scales into intervals and the hazard function is assumed to be constant within each interval. Using this trick, survival models can be fit using a Poisson regression model. This explanation can be found in more detail [here](https://onlinelibrary.wiley.com/doi/full/10.1111/insr.12214).

These models normally treat the time intervals as a factor since it estimates the intercept for each time interval. However we can also use a spline smoother to estimate the baseline hazard as a continuous function. We will demonstrate both.

First though, we need to do some data rearranging. The dataset currently has 1 row per larvae, but we need the dataset to be 1 row for each timepoint where the larvae is alive.

```{r brms_pem}
# prepare the dataset
final_time <- max(d$time_of_death)

events_only <- d %>%
  filter(status == 1) %>%
  pull(time_of_death) %>%
  unique() %>%
  sort()

cut_events <- c(events_only, final_time) %>% unique()

d <- mutate(d, id = 1:n())

d_new <- survSplit(
  formula = Surv(time_of_death, status) ~ .,
  data = d,
  cut = cut_events) %>%
  rename(tstop = time_of_death) %>%
  mutate(tduration = tstop - tstart)

# check this gets the same answer
model3.2 <- coxph(Surv(tstart, tstop, status)~treat2, 
        data = d_new)

# fit the brms model using time interval as a factor
fit_brms_pem_fac <- brm(
  formula = status ~ treat2 + as.factor(tstop) + offset(log(tduration)) + (1|clone),
  family = poisson(),
  prior = set_prior('normal(0, 4)', class = 'b'), 
  data = d_new, 
  chains = 3, 
  iter = 2000)

# fit the brms model using time interval as a continuous variable
# number of knots is the length of cutpoints
fit_brms_pem_cont <- brm(
  formula = status ~ treat2 + as.factor(tstop) + offset(log(tduration)) + (1|clone),
  family = poisson(),
  prior = set_prior('normal(0, 4)', class = 'b'), 
  data = d_new, 
  chains = 3, 
  iter = 2000)
```

### Comparing estimates of hazard ratios across methods

We have now fit six different survival models to the same data, each with slightly different assumptions. We can compare the coefficients for each method. Specifically we will calculate the confidence interval for the hazard ratio between larvae injected with static vs. shaken bacteria. For the frequentist methods (**coxph** and **coxme**) we will calculate 95% confidence intervals, and for the bayesian methods we will calculate 95% credible intervals, but take the median as the point estimate as the distribution earlier in the code does not look completely normal.

```{r compare_hrs}
#| fig.width: 7
#| fig.height: 5

# calculate confidence interval for coxph
coxph_ci <- tibble(hr = exp(coef(model3)),
                 lower = exp(coef(model3) - (1.96 * sqrt(diag(vcov(model3))))),
                 upper = exp(coef(model3) + (1.96 * sqrt(diag(vcov(model3))))),
                 method = 'coxph')

# calculate confidence interval for coxme
coxme_ci <- tibble(hr = exp(coef(model_me)),
                 lower = exp(coef(model_me) - (1.96 * sqrt(diag(vcov(model_me))))),
                 upper = exp(coef(model_me) + (1.96 * sqrt(diag(vcov(model_me))))),
                 method = 'coxme')

# calculate credible intervals for the brms Cox model
brms_ci_cox <- brms_hr %>%
  median_qi(hazard_ratio) %>%
  select(hr = hazard_ratio, lower = .lower, upper = .upper) %>%
  mutate(method = 'brms_cox')

# calculate credible intervals for rstanarm M-splines model
rstanarm_ci <- mod_rstanarm %>%
  gather_draws(`treat2static`, regex = TRUE) %>%
  mutate(hazard_ratio = exp(.value)) %>%
  median_qi(hazard_ratio) %>%
  select(hr = hazard_ratio, lower = .lower, upper = .upper) %>%
  mutate(method = 'rstanarm_msplines')

# calculate credible intervals for brms PEM models
brms_ci_pemfac <- fit_brms_pem_fac %>%
  gather_draws(`b_treat2static`, regex = TRUE) %>%
  mutate(hazard_ratio = exp(.value)) %>%
  median_qi(hazard_ratio) %>%
  select(hr = hazard_ratio, lower = .lower, upper = .upper) %>%
  mutate(method = 'brms_pem_fac')

brms_ci_pemcont <- fit_brms_pem_cont %>%
  gather_draws(`b_treat2static`, regex = TRUE) %>%
  mutate(hazard_ratio = exp(.value)) %>%
  median_qi(hazard_ratio) %>%
  select(hr = hazard_ratio, lower = .lower, upper = .upper) %>%
  mutate(method = 'brms_pem_cont')

# combine datasets together
all_cis <- bind_rows(coxph_ci, coxme_ci, brms_ci_cox, brms_ci_pemcont, brms_ci_pemfac, rstanarm_ci)

# plot
ggplot(all_cis, aes(y = method, x = hr)) +
  geom_point(size = 3) +
  geom_linerange(aes(xmin = lower, xmax = upper)) +
  theme_bw(base_size = 14) +
  geom_vline(aes(xintercept = 1), linetype = 2) +
  labs(x = 'Hazard ratio') +
  xlim(c(0, 1.6))

```

Reassuringly all of these methods provide similar estimates of the hazard ratio, but the Cox proportional hazards model that does not account for random effects is much more confident in estimate than all the other methods that do account for non-independence between clones.

## So why bother with rstanarm and the Bayesian approach?

General overview

-   fully account for, visualise, and understand the uncertainty in the data
-   can get access to random effect survival curves as well as fixed effect survival curves
-   estimates are very easily manipulated allowing for complex, custom contrasts that are much harder to compute otheriwse
-   can compare individual curves to the AVERAGE curve to understand which treatments are generally more virulent than others
